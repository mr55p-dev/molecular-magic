# Molecular Magic

Working repository for modifications to the work done in https://github.com/sanha0213/MolE8

## Structure

- `feature_generation/` contains the source files for taking a `.plk` file and converting it into a saved numpy array `.npy` file
  - `clean_database.py` removes specific subsets of molecules based on calculated properties.
  - `create_features.py` calculates historgams and creates the vector representation.
- `model_training/` has the code for training models with the different configurations and experimental parameters. It references several files which correspond to modifications of the dataset, either in the cleaning or feature creation stages.
- `raw_analysis` is the code for taking the Gaussian16 output files for each molecule (one file for initial geometry, one for calculated geometry and energy, one for thermodynamic quantities) and parsing them into representation which is used by `feature_generation`. This is a really really inefficient process, and will probably be modified to keep only the relevant properties of each molecule saved as numeric or binary data.

## Requirements

`requirements.txt` is generated by `pipreqs`, as the development environment for an M1 mac with tensorflow is not exactly consistent with any other system.

## Openbabel

`openbabel` used in the project seems to be version `2.x.x` however this can't be verified due to no requirements file being included. Instead of using this it seems better to migrate to version `3.1.1` and moving forward take advantage of the `pybabel` API rather than the auto-generated C++ bindings. Some corrections which appear to be related to the version change are being made to the original code.

## Neural network models
`model_training/NN/NN.py` directory does not currently run, as it requires a CSV with each molecules stoicheometry after feature generation. I have no idea why this isn't included with the data that we have, but it shouldn't be too hard to implement at the end of `raw_analysis/create_features.py`.

Note that the files from `model_training/NN_CoulombMatr` work, as they do not implement the special train-test splitting which `NN` does. They both define a similar architecture, except `NN` contains more nodes in the hidden layers ($812$ vs $351$).

## Kernel Ridge Regression models
Some of the `model_training/KRR` experiments fail, and this seems to be due to an address boundary error in `sklearn`. Exits with `SIGSEV: Address boundary error`. Also, half of the files save a fitted kernel and the other half load fitted kernels and there is NO NAMING CONVENTION to help out distinguishing the two. I have removed all but one of the files, since they are all basically the same anyway.
